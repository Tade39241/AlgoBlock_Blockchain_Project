import requests
import json
import time
import csv
import datetime
import os

# Configuration
CONFIG_PATH = "network_data/network_config.json" # Path to the config file generated by network_launcher.py
OUTPUT_CSV = "pos_performance_data.csv"          # Name of the CSV file to save data
MONITOR_DURATION_SECONDS = 600                   # How long to monitor (e.g., 600 seconds = 10 minutes)
POLL_INTERVAL_SECONDS = 10                       # How often to query the nodes (e.g., every 10 seconds)

def get_node_endpoints(config_path):
    """Reads network config to get node web ports."""
    if not os.path.exists(config_path):
        print(f"Error: Network config file not found at {config_path}")
        print("Please run network_launcher.py first to generate the config.")
        return None
    try:
        with open(config_path, 'r') as f:
            config = json.load(f)

        endpoints = []
        # Ensure 'nodes' key exists and is a list
        for node_info in config.get("nodes", []):
            # Check if essential keys exist in node_info
            if all(k in node_info for k in ["id", "host", "web_port"]):
                endpoints.append({
                    "id": node_info["id"],
                    "stats_url": f"http://{node_info['host']}:{node_info['web_port']}/stats",
                    "perf_url": f"http://{node_info['host']}:{node_info['web_port']}/performance"
                })
            else:
                print(f"Warning: Skipping node info due to missing keys: {node_info}")
        return endpoints
    except json.JSONDecodeError as e:
        print(f"Error parsing config file {config_path}: {e}")
        return None
    except Exception as e:
        print(f"Error reading config file {config_path}: {e}")
        return None

def poll_endpoint(url):
    """Safely polls a URL endpoint and returns JSON data or None."""
    try:
        response = requests.get(url, timeout=5) # Add timeout for the request
        response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)
        return response.json()
    except requests.exceptions.Timeout:
        print(f"Warning: Timeout connecting to {url}.")
        return None
    except requests.exceptions.ConnectionError:
        print(f"Warning: Connection error for {url}. Is the node running?")
        return None
    except requests.exceptions.RequestException as e:
        print(f"Warning: Could not connect to {url}. Error: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"Warning: Could not decode JSON from {url}. Response: {response.text[:100]}... Error: {e}")
        return None
    except Exception as e:
        print(f"Warning: Unexpected error polling {url}. Error: {e}")
        return None


def main():
    endpoints = get_node_endpoints(CONFIG_PATH)
    if not endpoints:
        return

    all_data = []
    start_time = time.time()
    end_time = start_time + MONITOR_DURATION_SECONDS

    print(f"Starting monitoring for {MONITOR_DURATION_SECONDS} seconds...")
    print(f"Polling nodes every {POLL_INTERVAL_SECONDS} seconds.")
    print(f"Data will be saved to {OUTPUT_CSV}")

    try:
        while time.time() < end_time:
            current_timestamp_iso = datetime.datetime.now().isoformat()
            current_timestamp_unix = time.time()
            print(f"Polling at {current_timestamp_iso}...")

            for node in endpoints:
                node_id = node["id"]
                stats_data = poll_endpoint(node["stats_url"])
                perf_data = poll_endpoint(node["perf_url"])

                # Combine data, handling potential None values if polling failed
                record = {
                    "timestamp_iso": current_timestamp_iso,
                    "timestamp_unix": current_timestamp_unix,
                    "node_id": node_id,
                    "cpu_percent": stats_data.get("cpu_percent", None) if stats_data else None,
                    "memory_percent": stats_data.get("memory_percent", None) if stats_data else None,
                    "disk_percent": stats_data.get("disk_percent", None) if stats_data else None,
                    "blockchain_height": stats_data.get("blockchain_height", None) if stats_data else None,
                    "mempool_size": stats_data.get("mempool_size", None) if stats_data else None,
                    "total_transactions": stats_data.get("total_transactions", None) if stats_data else None,
                    "last_block_timestamp": stats_data.get("last_block_timestamp", None) if stats_data else None,
                    "estimated_tps": perf_data.get("estimated_tps", None) if perf_data else None,
                    "average_block_time": perf_data.get("average_block_time", None) if perf_data else None,
                    "avg_tx_per_block": perf_data.get("average_transactions_per_block", None) if perf_data else None,
                    "blocks_considered": perf_data.get("blocks_considered", None) if perf_data else None,
                    "valid_block_intervals": perf_data.get("valid_block_intervals", None) if perf_data else None,
                }
                all_data.append(record)

            # Wait for the next poll interval
            # Adjust sleep time to account for polling duration, aiming for POLL_INTERVAL_SECONDS between starts of polling cycles
            elapsed_time = time.time() - current_timestamp_unix
            sleep_time = max(0, POLL_INTERVAL_SECONDS - elapsed_time)
            time.sleep(sleep_time)

    except KeyboardInterrupt:
        print("\nMonitoring interrupted by user.")
    finally:
        print(f"Monitoring finished. Saving collected data ({len(all_data)} records) to {OUTPUT_CSV}...")

        # Write data to CSV
        if all_data:
            # Ensure consistent field order based on the first record
            fieldnames = list(all_data[0].keys())
            try:
                with open(OUTPUT_CSV, 'w', newline='') as csvfile:
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(all_data)
                print("Data saved successfully.")
            except IOError as e:
                print(f"Error writing CSV file: {e}")
            except Exception as e:
                 print(f"An unexpected error occurred during CSV writing: {e}")
        else:
            print("No data collected.")

if __name__ == "__main__":
    main()